{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "410afaec-214e-47b1-bac4-a441cf8f0844",
   "metadata": {},
   "source": [
    "# ML Case Study\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6af9c0b-1db1-40e8-94ea-6907b6b11f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ydata-profiling==4.7.0\n",
    "!pip install numba==0.59.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b2509e-9b3b-4b2f-9367-03cac2cd2596",
   "metadata": {},
   "source": [
    "## Load .csv to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3920f2-149d-4839-970e-e376311aed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "path = \"./data\"\n",
    "file_name = \"housing_data.csv\"\n",
    "\n",
    "df = pd.read_csv(os.path.join(path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a59c32-5b7b-4e7d-a30a-da4072afca8c",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf0f792-fd4c-4ccb-9a72-641397cdb3bb",
   "metadata": {},
   "source": [
    "Begin with a simple visualization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2746a63-df20-40a8-a578-6bf4959d233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331dbcfe-9fea-4195-8f6d-8a367a1484fb",
   "metadata": {},
   "source": [
    "Remapping furnishingstatus column to digits. The default format is an issue for ydata_profiling to calculate correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f374c5f-f6fd-4451-bee3-d0d2dfd09559",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"furnished\": \"0\", \"semi-furnished\": \"1\", \"unfurnished\": \"2\"}\n",
    "df['furnishingstatus'] = df['furnishingstatus'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936cb4b-a117-4429-b8a1-44a50b9b0d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df, title=\"Data Report\")\n",
    "profile.to_file(\"data_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c9bd4-366d-41af-8024-2b29c7917c0c",
   "metadata": {},
   "source": [
    "The report shows that there are no missing values.\n",
    "\n",
    "One of the highlighted features is a high correlation between price and area, which means that area will mostly determine the price of the house.\\\n",
    "Other notable traits are highly imbalanced columns - bathrooms and hotwaterheating.\n",
    "\n",
    "Some columns are described as categorical by ydata_profiling due to their low range of possible values (bathrooms, stories, parking), although they may as well be treated as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43d30d-7881-4a1c-b170-d8b7c5507419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "columns = ['price', 'area']\n",
    "sns.pairplot(df[columns])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a0e03b-4a3d-48d1-b79d-c0fa184af83d",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedbcc4c-3b7b-4ae8-a0ac-e27f90ce3cbc",
   "metadata": {},
   "source": [
    "### Find Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5087d050-60d9-4c7d-8a7e-ee7cd061e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(8, 10))\n",
    "sns.boxplot(df['price'],    ax=axes[0, 0])\n",
    "axes[0, 0].set_title('price')\n",
    "sns.boxplot(df['area'],     ax=axes[0, 1])\n",
    "axes[0, 1].set_title('area')\n",
    "sns.boxplot(df['bedrooms'], ax=axes[1, 0])\n",
    "axes[1, 0].set_title('bedrooms')\n",
    "sns.boxplot(df['bathrooms'],ax=axes[1, 1])\n",
    "axes[1, 1].set_title('bathrooms')\n",
    "sns.boxplot(df['stories'],  ax=axes[2, 0])\n",
    "axes[2, 0].set_title('stories')\n",
    "sns.boxplot(df['parking'],  ax=axes[2, 1])\n",
    "axes[2, 1].set_title('parking')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c816e98-3769-4d9b-a456-850389474657",
   "metadata": {},
   "source": [
    "As boxplots show, some columns contain visible outliers that, if left unchanged, can negatively affect model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972487a4-131a-44d1-ad48-41dc3f882b60",
   "metadata": {},
   "source": [
    "### Perform IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a677639-c482-4f40-88a1-878a8cf0db72",
   "metadata": {},
   "source": [
    "In order to address outliers it's necessary to choose an adequate method. Methods such as z-score are adjusted to be used with normal distributions.\n",
    "Due to bell curves being visibly skewed and the dataset being quite numerous, I chose the Interquartile Range method which is more robust to such data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c9bd7-cd37-4456-8fab-4029dd3dbb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "columns = ['price','area']\n",
    "\n",
    "for col in columns:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    threshold = 1.5\n",
    "    df = df[(Q1 - threshold * IQR < df[col]) & (df[col] < Q3 + threshold * IQR)]\n",
    "\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0b3a7-3d87-45a7-8a9c-333682e7880c",
   "metadata": {},
   "source": [
    "To perform a linear regression it's necessary to take care of boolean and categorical variables.\\\n",
    "Therefore, boolean variables are converted to 0 and 1 values and categorical column gets OneHot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f18a9b-ef47-45de-99d1-4cb1e82cba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert boolean values to int64\n",
    "\n",
    "df = pd.get_dummies(df, columns=['furnishingstatus'])\n",
    "column_names = {\n",
    "    'furnishingstatus_0':'furnished',\n",
    "    'furnishingstatus_1':'semi-furnished',\n",
    "    'furnishingstatus_2':'unfurnished'\n",
    "}\n",
    "df.rename(columns=column_names, inplace=True)\n",
    "\n",
    "boolean_cols = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea', 'furnished', 'semi-furnished', 'unfurnished']\n",
    "df[boolean_cols] = df[boolean_cols].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c5d43-be36-4f36-9034-4d41639f1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(8, 10))\n",
    "sns.boxplot(df['price'],    ax=axes[0, 0])\n",
    "axes[0, 0].set_title('price')\n",
    "sns.boxplot(df['area'],     ax=axes[0, 1])\n",
    "axes[0, 1].set_title('area')\n",
    "sns.boxplot(df['bedrooms'], ax=axes[1, 0])\n",
    "axes[1, 0].set_title('bedrooms')\n",
    "sns.boxplot(df['bathrooms'],ax=axes[1, 1])\n",
    "axes[1, 1].set_title('bathrooms')\n",
    "sns.boxplot(df['stories'],  ax=axes[2, 0])\n",
    "axes[2, 0].set_title('stories')\n",
    "sns.boxplot(df['parking'],  ax=axes[2, 1])\n",
    "axes[2, 1].set_title('parking')\n",
    "\n",
    "columns = ['price', 'area']\n",
    "sns.pairplot(df[columns])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60fe3d1-ca56-4b3c-a343-c86ec87ba195",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dab027-5018-41f6-b7b4-7af5b4f71367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 2)\n",
    "\n",
    "numeric_columns = X.select_dtypes(include=['int64']).columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numeric_transformer, numeric_columns),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfffcd-df1c-45ea-9a7e-90a763a113ce",
   "metadata": {},
   "source": [
    "## Model Training & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ade35ab-6b50-4562-a14e-e52a775961ff",
   "metadata": {},
   "source": [
    "To run the regression, I used Linear Regression, and two ensemble models - Random Forest and Gradient Boost.\n",
    "While using Random Forest / Gradient Boost it's usually unnecessary to use standard scaler. I decided to keep it here since it increases model's performance slightly, which means that all the models presented here use the same preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a9f49a-21ee-4275-ad36-02c61eef0c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boost': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Price and predicted price comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "fig.subplots_adjust(hspace = 0.2)\n",
    "fig.suptitle('Real and Predicted prices comparison', fontsize=16)\n",
    "\n",
    "# QQ plot\n",
    "fig2, axes2 = plt.subplots(2, 2, figsize=(12, 12))\n",
    "fig2.subplots_adjust(hspace = 0.2)\n",
    "fig2.suptitle('QQ plot', fontsize=16)\n",
    "\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    #Print Evaluation scores\n",
    "    print(f\"{name}\")\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred):.3f}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False):.3f}\")\n",
    "    print(f\"MAPE: {np.mean(np.abs((y_test - y_pred) / y_test)) * 100}\")\n",
    "    print(f\"R^2 Score: {r2_score(y_test, y_pred):.3f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Price and predicted price comparison\n",
    "    axes[i//2,i%2].scatter(y_test, y_pred)\n",
    "    axes[i//2,i%2].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='black', lw=2)\n",
    "    axes[i//2,i%2].set_title(name)\n",
    "    axes[i//2,i%2].set_xlabel('Price')\n",
    "    axes[i//2,i%2].set_ylabel('Predicted price')\n",
    "\n",
    "    # QQ plot\n",
    "    residuals = y_test - y_pred\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes2[i//2,i%2])\n",
    "    axes2[i//2,i%2].set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f46d04-56e6-4dff-acb5-4f4f98f2c0d3",
   "metadata": {},
   "source": [
    "The above graphs compare actual and predicted prices. The closer the values are to the straight line, the better.\n",
    "The QQ plot shows how close the distribution of residuals (differences between real and predicted values) are to the normal distribution.\n",
    "Having residuals normally distributed is a key assumption in regression, so the closer they are to the straight line, the better the fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e395a-058c-430b-868d-2e5f39a5e6ab",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2276c4-eef7-4bec-9b6b-5a25091939e2",
   "metadata": {},
   "source": [
    "Feature importance analysis shows that all variables except for hotwaterheating correlate with house prices, where the area is the most significant one.\n",
    "\n",
    "While the performance of the presented models (except for the single decision tree) is very similar, Gradient Boosting Regressor proved to be the best-performing model, providing the lowest price prediction errors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
